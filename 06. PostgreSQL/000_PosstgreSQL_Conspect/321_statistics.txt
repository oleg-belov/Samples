
ЧИСЛО СТРОК
~~~~~~~~~~~

Создадим БД и таблицу с неравномерно распределенными данными.
Мы будем эмулировать наблюдения за температурой в течении нескольких лет.

        => create database db17;
        CREATE DATABASE

        => \c db17
        You are now connected to database "db17" as user "postgres".

        => create table weather(id serial primary key, observation_date date, temperature integer);
        CREATE TABLE

        => insert into weather(observation_date, temperature)
        => select gen.d,
        =>       -cos( extract(day from gen.d - '2010-01-01 00:00:00'::timestamp) / 365.0 * 2.0 * pi() )*30.0 + (random()*6.0-3.0)
        => from   generate_series('2000-01-01 00:00:00'::timestamp,'2015-12-31 00:00:00'::timestamp, '1 day') as gen(d);
        INSERT 0 5844

.......................................................................

У нас получилось вот такое распределение температуры по месяцам:

        => select extract(month from observation_date) mon, min(temperature), round(avg(temperature),1), max(temperature) from weather group by 1 order by 1;
         mon | min | round | max 
        -----+-----+-------+-----
           1 | -33 | -28.8 | -24
           2 | -29 | -21.7 | -14
           3 | -19 |  -9.1 |   2
           4 |  -5 |   6.6 |  17
           5 |  11 |  20.1 |  28
           6 |  23 |  28.2 |  33
           7 |  24 |  28.9 |  33
           8 |  13 |  21.4 |  29
           9 |  -3 |   8.5 |  18
          10 | -17 |  -7.1 |   4
          11 | -28 | -20.4 | -12
          12 | -33 | -28.4 | -23
        (12 rows)
        

.......................................................................

Причем значения температуры встречаются с разной частотой:

        => select temperature, count(*) from weather where temperature >= 0 group by temperature order by temperature;
         temperature | count 
        -------------+-------
                   0 |    64
                   1 |    66
                   2 |    65
                   3 |    57
                   4 |    64
                   5 |    77
                   6 |    64
                   7 |    58
                   8 |    70
                   9 |    71
                  10 |    63
                  11 |    62
                  12 |    75
                  13 |    61
                  14 |    65
                  15 |    81
                  16 |    70
                  17 |    86
                  18 |    93
                  19 |    71
                  20 |    84
                  21 |    90
                  22 |    89
                  23 |    91
                  24 |    90
                  25 |   124
                  26 |   140
                  27 |   209
                  28 |   153
                  29 |   167
                  30 |   144
                  31 |   117
                  32 |    74
                  33 |    15
        (34 rows)
        

.......................................................................

Проанализируем таблицу. Значение параметра, управляющего размером
статистики, по умолчанию равно 100:

        => show default_statistics_target;
         default_statistics_target 
        ---------------------------
         100
        (1 row)
        

        => analyze weather;
        ANALYZE

.......................................................................

Теперь посмотрим на оценку кардинальности в простом случае -
запрос без предикатов.

        => explain select * from weather;
                                 QUERY PLAN                         
        ------------------------------------------------------------
         Seq Scan on weather  (cost=0.00..87.44 rows=5844 width=12)
        (1 row)
        

Точное значение:

        => select count(*) from weather;
         count 
        -------
          5844
        (1 row)
        

.......................................................................

Оптимизатор получает значение из pg_class, куда его записывается
при анализе:

        => select reltuples from pg_class where relname = 'weather';
         reltuples 
        -----------
              5844
        (1 row)
        

На самом деле при анализе таблицы учитывается 300*default_statistics_target
строк, поэтому в данном случае оценка всегда будет точной.

.......................................................................

ДОЛЯ NULL-ЗНАЧЕНИЙ
~~~~~~~~~~~~~~~~~~

Что, если часть значений будет содержать null?

        => update weather set temperature = null where mod(id,100) = 0;
        UPDATE 58

        => analyze weather;
        ANALYZE

        => explain select * from weather where temperature is null;
                                QUERY PLAN                        
        ----------------------------------------------------------
         Seq Scan on weather  (cost=0.00..87.44 rows=58 width=12)
           Filter: (temperature IS NULL)
        (2 rows)
        

.......................................................................

Оценка оптимизатора получена с учетом доли null-значений:

        => select null_frac from pg_stats where tablename = 'weather' and attname = 'temperature';
         null_frac  
        ------------
         0.00992471
        (1 row)
        

Умножив селективность на общее число строк, получаем оценку кардинальности:

        => select c.reltuples * s.null_frac
        => from   pg_class c, pg_stats s
        => where  c.relname = 'weather' and s.tablename = c.relname and s.attname = 'temperature';
         ?column? 
        ----------
               58
        (1 row)
        

.......................................................................

НАИБОЛЕЕ ЧАСТЫЕ ЗНАЧЕНИЯ
~~~~~~~~~~~~~~~~~~~~~~~~

Если значение есть в списке наиболее частых значений, то селективность
можно узнать непосредственно из статистики. Пример:

        => explain select * from weather where temperature = 27;
                                 QUERY PLAN                         
        ------------------------------------------------------------
         Seq Scan on weather  (cost=0.00..102.05 rows=208 width=12)
           Filter: (temperature = 27)
        (2 rows)
        

Точное значение:

        => select count(*) from weather where temperature = 27;
         count 
        -------
           208
        (1 row)
        

.......................................................................

Вот как выглядит список наиболее частых значений и частота их
втречаемости:

        => \x
        Expanded display is on.

        => select most_common_vals, most_common_freqs from pg_stats where tablename = 'weather' and attname = 'temperature';
        -[ RECORD 1 ]-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
        most_common_vals  | {27,-28,-27,29,-29,28,-30,30,26,-25,-26,25,31,-31,-24,-23,-21,-22,18,23,21,24,22,17,-19,-17,-12,20,-16,15,-32,-15,5,12,32,-9,-6,19,8,-13,9,16,-20,-18,1,2,-10,4,14,-14,-4,0,6,10,11,13,-5,7,-8,-3,3,-7,-1,-11,-2,-33,33}
        most_common_freqs | {0.0355921,0.0302875,0.0284052,0.028063,0.0278919,0.0260096,0.0242984,0.0242984,0.0239562,0.0231006,0.022245,0.020705,0.0198494,0.0186516,0.0183094,0.0167693,0.0167693,0.016256,0.0157426,0.0155715,0.0152293,0.0150582,0.0148871,0.0147159,0.0143737,0.0143737,0.0142026,0.0142026,0.0140315,0.0136893,0.0135181,0.0131759,0.0130048,0.0126626,0.0126626,0.0124914,0.0123203,0.0121492,0.0119781,0.011807,0.011807,0.011807,0.0112936,0.0112936,0.0112936,0.0111225,0.0109514,0.0109514,0.0109514,0.0107803,0.0107803,0.0107803,0.0107803,0.0106092,0.0106092,0.0104381,0.0100958,0.00992471,0.00975359,0.00975359,0.00958248,0.00941136,0.00941136,0.00889802,0.00770021,0.00342231,0.00256674}
        

        => \x
        Expanded display is off.

Значение параметра default_statistics_target определяет максимальное
число значений. В нашем случае сотни хватает, чтобы хранить все значения.

.......................................................................

Кардинальность вычисляется как число строк, умноженное на частоту значения:

        => select c.reltuples * s.most_common_freqs[array_position((s.most_common_vals::text::int[]),27)]
        => from   pg_class c, pg_stats s
        => where  c.relname = 'weather' and s.tablename = c.relname and s.attname = 'temperature';
         ?column? 
        ----------
              208
        (1 row)
        

.......................................................................

ЧИСЛО УНИКАЛЬНЫХ ЗНАЧЕНИЙ
~~~~~~~~~~~~~~~~~~~~~~~~~

Если же указанного значения нет в списке наиболее частых, то оно вычисляется
исходя из предположения, что все данные, кроме наиболее частых,
распределены равномерно.

Поскольку в нашем примере список содержит вообще все значения,
изменим значение параметра (на уровне столбца) и проанализируем
таблицу заново.

        => alter table weather alter temperature set statistics 10;
        ALTER TABLE

        => analyze weather;
        ANALYZE

.......................................................................

Вот как выглядит список наиболее частых значений теперь:

        => \x
        Expanded display is on.

        => select most_common_vals, most_common_freqs from pg_stats where tablename = 'weather' and attname = 'temperature';
        -[ RECORD 1 ]-----+-----------------------------------------------------------------------------------------------------
        most_common_vals  | {27,-28,-27,29,-29,28,-30,30,26,-25}
        most_common_freqs | {0.0355921,0.0302875,0.0284052,0.028063,0.0278919,0.0260096,0.0242984,0.0242984,0.0239562,0.0231006}
        

        => \x
        Expanded display is off.

.......................................................................

Например, в этом списке нет значения 0 - оно встречается не так часто.

        => explain select * from weather where temperature = 0;
                                QUERY PLAN                         
        -----------------------------------------------------------
         Seq Scan on weather  (cost=0.00..102.05 rows=74 width=12)
           Filter: (temperature = 0)
        (2 rows)
        

Точное значение:

        => select count(*) from weather where temperature = 0;
         count 
        -------
            63
        (1 row)
        

.......................................................................

Для получения оценки вычислим сумму частот наиболее частых значений:

        => select sum(f) from pg_stats s, unnest(s.most_common_freqs) f
        => where  s.tablename = 'weather' and s.attname = 'temperature';
           sum    
        ----------
         0.271903
        (1 row)
        

И запомним это значение:

        => select sum(f) as mcf from pg_stats s, unnest(s.most_common_freqs) f
        => where  s.tablename = 'weather' and s.attname = 'temperature'
        => \gset

.......................................................................

На менее частые значения приходятся оставшиеся строки.
Поскольку мы исходим из предположения о равномерности распределения
менее частых значений, селективность будет равна 1/nd,
где nd - число уникальных значений:

        => select n_distinct from pg_stats s where s.tablename = 'weather' and s.attname = 'temperature';
         n_distinct 
        ------------
                 67
        (1 row)
        

.......................................................................

Учитывая, что из этих значений 10 входят в список наиболее частых,
получаем следующую оценку:

        => select c.reltuples * (1 - s.null_frac) * (1 - :mcf) / (s.n_distinct - 10)
        => from   pg_class c, pg_stats s
        => where  c.relname = 'weather' and s.tablename = c.relname and s.attname = 'temperature';
             ?column?     
        ------------------
         73.9082323335389
        (1 row)
        

.......................................................................

ГИСТОГРАММА
~~~~~~~~~~~

При условиях "больше" и "меньше" для оценки будет использоваться
список наиболее частых значений, или гистограмма, или оба способа вместе.
Гистограмма стоится так, чтобы не включать наиболее частые значения и null:

        => select histogram_bounds from pg_stats s where s.tablename = 'weather' and s.attname = 'temperature';
                   histogram_bounds           
        --------------------------------------
         {-33,-24,-19,-13,-7,0,7,13,18,23,33}
        (1 row)
        

Число корзин гистограммы определяется параметром статистики, а границы
выбираются так, чтобы в каждой корзине находилось примерно одинаковое
количество значений.

.......................................................................

Рассмотрим пример:

        => explain select * from weather where temperature between 0 and 13;
                                 QUERY PLAN                         
        ------------------------------------------------------------
         Seq Scan on weather  (cost=0.00..116.66 rows=839 width=12)
           Filter: ((temperature >= 0) AND (temperature <= 13))
        (2 rows)
        

Точное значение:

        => select count(*) from weather where temperature between 0 and 13;
         count 
        -------
           909
        (1 row)
        

.......................................................................

Не будем приводить точный расчет, но:
* указанный интервал занимает примерно 2 корзины гистограммы из 10;
* указанный интервал не попадает на наиболее частые значения.
Поэтому кардинальность вычисляется примерно так:

        => select c.reltuples * (1 - s.null_frac) * (1 - :mcf) * (2.0 / 10.0)
        => from   pg_class c, pg_stats s
        => where  c.relname = 'weather' and s.tablename = c.relname and s.attname = 'temperature';
             ?column?     
        ------------------
         842.553848602343
        (1 row)
        

На самом деле учитываются и не полностью занятые корзины (с помощью
линейной аппроксимации).

.......................................................................

СОЕДИНЕНИЯ
~~~~~~~~~~

Селективность соединения - доля строк от декартового произведения
двух таблиц. Ее сложнее считать, чем селективность ограничивающих
условий, и точность обычно получается ниже.

Мы рассмотрим один простой пример.
Пусть имеется еще одна таблица, в которой могут храниться комментарии
к наблюдениям:

        => create table notes(weather_id integer references weather(id), note text);
        CREATE TABLE

        => insert into notes select id, 'test' from weather, generate_series(1,3) where temperature > 25 or temperature < -25;
        INSERT 0 5991

        => analyze notes;
        ANALYZE

.......................................................................

Пример:

        => explain select * from weather w join notes n on (w.id = n.weather_id);
                                        QUERY PLAN                                
        --------------------------------------------------------------------------
         Hash Join  (cost=160.49..332.78 rows=5991 width=21)
           Hash Cond: (n.weather_id = w.id)
           ->  Seq Scan on notes n  (cost=0.00..89.91 rows=5991 width=9)
           ->  Hash  (cost=87.44..87.44 rows=5844 width=12)
                 ->  Seq Scan on weather w  (cost=0.00..87.44 rows=5844 width=12)
        (5 rows)
        

Точное число строк:

        => select count(*) from weather w join notes n on (w.id = n.weather_id);
         count 
        -------
          5991
        (1 row)
        

.......................................................................

В таком простом случае оценка селективности получена как min(1/nd1, 1/nd2).

        => select s1.n_distinct, s2.n_distinct
        => from   pg_stats s1, pg_stats s2
        => where  s1.tablename = 'weather' and s1.attname = 'id'
        => and    s2.tablename = 'notes' and s2.attname = 'weather_id';
         n_distinct | n_distinct 
        ------------+------------
                 -1 |  -0.333333
        (1 row)
        

Обратите внимание, что в данном случае число уникальных значений
дано как доля от всех значений.

.......................................................................

Итоговая оценка:

        => select c1.reltuples * c2.reltuples * 
        =>        least(-1/s1.n_distinct/c1.reltuples, -1/s2.n_distinct/c2.reltuples)
        => from   pg_class c1, pg_stats s1, pg_class c2, pg_stats s2
        => where  c1.relname = 'weather' and s1.tablename = c1.relname and s1.attname = 'id'
        => and    c2.relname = 'notes' and s2.tablename = c2.relname and s2.attname = 'weather_id';
         ?column? 
        ----------
             5991
        (1 row)
        

В общем случае учитывается также наличие значений null, наличие списка
наиболее частых значений и т. д.
./dba2_17_statistics.sh: line 287: с: command not found
./dba2_17_statistics.sh: line 289: с: command not found
КОРРЕЛИРОВАННЫЕ ПРЕДИКАТЫ
~~~~~~~~~~~~~~~~~~~~~~~~~

Рассмотрим пример:

        => explain select * from weather where extract(month from observation_date) = 1 and temperature >= 0;
                                                                       QUERY PLAN                                                               
        ----------------------------------------------------------------------------------------------------------------------------------------
         Seq Scan on weather  (cost=0.00..145.88 rows=15 width=12)
           Filter: ((temperature >= 0) AND (date_part('month'::text, (observation_date)::timestamp without time zone) = '1'::double precision))
        (2 rows)
        

Оптимизатор ожидает, что в январе будет 14 дней с плюсовой температурой.
Почему так?

.......................................................................

Дело в том, что селективность условий рассчитывается в предположении,
что предикаты не коррелированы.
Первое условие:

        => explain select * from weather where extract(month from observation_date) = 1;
                                                          QUERY PLAN                                                   
        ---------------------------------------------------------------------------------------------------------------
         Seq Scan on weather  (cost=0.00..131.27 rows=29 width=12)
           Filter: (date_part('month'::text, (observation_date)::timestamp without time zone) = '1'::double precision)
        (2 rows)
        

Планировщик предполагает выбрать 29 строк. Однако он ошибается, и довольно сильно:

        => select count(*) from weather where extract(month from observation_date) = 1;
         count 
        -------
           496
        (1 row)
        

.......................................................................

Проблема здесь в том, что планировщик ничего не знает про семантику
функции extract. С тем же успехом можно взять любую другую:

        => explain select * from weather where random() = 1;
                                QUERY PLAN                         
        -----------------------------------------------------------
         Seq Scan on weather  (cost=0.00..116.66 rows=29 width=12)
           Filter: (random() = '1'::double precision)
        (2 rows)
        

Оценка предикатов вида "функция = константа" оценивается просто как 0.5%
от общего числа строк:

        => select count(*) * 0.005 from weather;
         ?column? 
        ----------
           29.220
        (1 row)
        

.......................................................................

Второе условие:

        => explain select * from weather where temperature >= 0;
                                 QUERY PLAN                          
        -------------------------------------------------------------
         Seq Scan on weather  (cost=0.00..102.05 rows=2904 width=12)
           Filter: (temperature >= 0)
        (2 rows)
        

Ожидается примерно 1/2 часть строк - здесь оценка нормальная.

.......................................................................

Но итоговая селективность рассчитывается как произведение селективностей,
что еще больше усугубляет ошибку. То есть взаимосвязь двух условий
не принимается во внимание.

К сожалению, пока в PostgreSQL нет возможности учитывать корреляцию
предикатов, так что подобных запросов следует избегать. Но иногда
дело может спасти функциональный индекс, построенный по двум полям -
для функциональных индексов собирается отдельная статистика.

        => create index weather_array_idx on weather((
        =>   array[ extract(month from observation_date), temperature ]
        => ));
        CREATE INDEX

        => analyze weather;
        ANALYZE

.......................................................................

Статистика хранится в pg_stats в отдельной строке:

        => select n_distinct from pg_stats where tablename = 'weather_array_idx';
         n_distinct 
        ------------
                210
        (1 row)
        

.......................................................................

Чтобы такая статистика учлась оптимизатором, запрос надо переписать:

        => explain select * from weather
        => where array[extract(month from observation_date),temperature]
        =>   between array[1::double precision,0]
        =>       and array[1::double precision,100];
                                                                                                                                                                 QUERY PLAN                                                                                                                                                          
        -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
         Index Scan using weather_array_idx on weather  (cost=0.28..8.30 rows=1 width=12)
           Index Cond: ((ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] >= '{1,0}'::double precision[]) AND (ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] <= '{1,100}'::double precision[]))
        (2 rows)
        

Получили оценку в одну строку - это минимальная оценка, которую
дает оптимизатор.

.......................................................................

Попробуем заменить январь на июль:

        => explain select * from weather
        => where array[extract(month from observation_date),temperature]
        =>   between array[7::double precision,0]
        =>       and array[7::double precision,100];
                                                                                                                                                                    QUERY PLAN                                                                                                                                                             
        -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
         Bitmap Heap Scan on weather  (cost=21.46..65.61 rows=505 width=12)
           Recheck Cond: ((ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] >= '{7,0}'::double precision[]) AND (ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] <= '{7,100}'::double precision[]))
           ->  Bitmap Index Scan on weather_array_idx  (cost=0.00..21.33 rows=505 width=0)
                 Index Cond: ((ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] >= '{7,0}'::double precision[]) AND (ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] <= '{7,100}'::double precision[]))
        (4 rows)
        

И эта оценка адекватна, точное значение:

        => select count(*) from weather where array[extract(month from observation_date),temperature] between array[7::double precision,0] and array[7::double precision,100];
         count 
        -------
           490
        (1 row)
        

.......................................................................

Можно улучшить оценки, увеличив параметр статистики. Для индекса это
можно сделать примерно так же, как и для таблицы:

        => alter index weather_array_idx alter "array" set statistics 300;
        ALTER INDEX

        => analyze weather;
        ANALYZE

Надо только учитывать, что имя "столбца" будет разным для разных
типов данных.

.......................................................................

Проверяем:

        => explain select * from weather where array[extract(month from observation_date),temperature] between array[7::double precision,0] and array[7::double precision,100];
                                                                                                                                                                    QUERY PLAN                                                                                                                                                             
        -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
         Bitmap Heap Scan on weather  (cost=21.33..65.09 rows=492 width=12)
           Recheck Cond: ((ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] >= '{7,0}'::double precision[]) AND (ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] <= '{7,100}'::double precision[]))
           ->  Bitmap Index Scan on weather_array_idx  (cost=0.00..21.20 rows=492 width=0)
                 Index Cond: ((ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] >= '{7,0}'::double precision[]) AND (ARRAY[date_part('month'::text, (observation_date)::timestamp without time zone), (temperature)::double precision] <= '{7,100}'::double precision[]))
        (4 rows)
        

.......................................................................

Конец демонстрации.

.......................................................................

        => \q
